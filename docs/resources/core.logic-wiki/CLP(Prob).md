We should look at [HANSEI](http://okmij.org/ftp/kakuritu/index.html), [Church](http://projects.csail.mit.edu/church/wiki/Church), [Prism](http://sato-www.cs.titech.ac.jp/prism/), [ProbLog](http://dtai.cs.kuleuven.be/problog/), [CLP(BN)](http://www.cos.ufrj.br/~vitor/Yap/clpbn/uai03.ps) and all of the other interesting approaches to probabilistic logic programming.

[Markov Chain Monte Carlo & Gibbs Sampling](http://en.wikipedia.org/wiki/Gibbs_sampling) seem to be the hot topic these days. It's interesting that some promising work has been done executing this stuff on GPUs.

# Existing Projects in the space
## Nils Bertschinger's Work
Nils has already written a really neat probabilistic embedding in Clojure 
* The [repo](https://github.com/bertschi/ProbClojureNice) is on GitHub
* A [paper](http://ozk.unizd.hr/proceedings/index.php/els/article/view/102/106) describing the work
* This is based on the bher compiler for Church using the approach described [here](http://www.stanford.edu/~ngoodman/papers/WSG-AIStats11.pdf). There's also a [video](http://videolectures.net/aistats2011_wingate_lightweight/)

The approach is to create a program where each stochastic element (choice point), and its dependent stochastic elements are annotated.  The whole program is considered as generating a single sample in a MH algorithm.  Proposals are generated by selecting a choice point, making a local proposal to its RV, and computing the downstream changes, which is then accepted/rejected in the MH framework.

### Ramblings 
* The MH proposals are generated locally.  Can this be improved ?  Can HMC be applied ?
* A possible improvement is that currently the coder must manually tag all the choice-point dependencies.  Perhaps if the computation is specified using a structure like Flow or Graph this could be avoided ?

## Church
* A good [video](http://videolectures.net/aaai2012_tenenbaum_grow_mind/) on Church. 
* A good [tutorial](http://projects.csail.mit.edu/church/wiki/Probabilistic_Models_of_Cognition)

## Infer.net
Infer.net is Microsoft's probabilistic programming language in F#
* The [webpage](http://research.microsoft.com/en-us/um/cambridge/projects/infernet/) links to many good resources on the area.

## Stan
New project based around Hamiltonian Monte Carlo, which has advantages in situations with correlated variables.
* The [Stan](http://mc-stan.org/) project
* The [Reference Manual](http://stan.googlecode.com/files/stan-reference-1.3.0.pdf)
* The [code repo](https://github.com/stan-dev/stan/)

## Bugs and JAGS
A probabilistic programming language, based on Gibbs Sampling, that has been in use for a long time is BUGS.  A more recent implementation is JAGS, which largely supercedes BUGS.  The beauty of these are that you can actually get them up and running in R without much effort.
* The [rjags](http://cran.r-project.org/web/packages/rjags/index.html) R package lets you quickly do some probabilistic programming.  In particular, you can actually run the examples in the blog post below.
* A good [blog post](http://zinkov.com/posts/2012-06-27-why-prob-programming-matters/) on the sort of model BUGS/JAGS can represent.
* The jags [repo](http://mcmc-jags.sourceforge.net/)
* The jags [user manual](http://sourceforge.net/projects/mcmc-jags/files/Manuals/3.x/jags_user_manual.pdf/download) is easy to miss!